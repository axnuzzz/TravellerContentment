{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T17:45:07.638800Z",
     "iopub.status.busy": "2023-12-17T17:45:07.637927Z",
     "iopub.status.idle": "2023-12-17T17:45:20.106533Z",
     "shell.execute_reply": "2023-12-17T17:45:20.105448Z",
     "shell.execute_reply.started": "2023-12-17T17:45:07.638762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read and preprocess data\n",
    "def preprocess_data(data):\n",
    "    # Impute NaN values using median\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    data['Arrival Delay in Minutes'] = imputer.fit_transform(data[['Arrival Delay in Minutes']])\n",
    "\n",
    "train_data = pd.read_csv('/kaggle/input/testtrain2/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/testtrain2/test.csv')\n",
    "\n",
    "# Preprocess data\n",
    "preprocess_data(train_data)\n",
    "preprocess_data(test_data)\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=[\"Gender\", \"Traveler Type\", \"Type of Travel\", \"Class\"])\n",
    "test_data = pd.get_dummies(test_data, columns=[\"Gender\", \"Traveler Type\", \"Type of Travel\", \"Class\"])\n",
    "\n",
    "# EDA: Box Plots for Numeric Features\n",
    "numeric_features = train_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "for feature in numeric_features:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=train_data, x=feature)\n",
    "    plt.title(f'Box Plot of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.show()\n",
    "\n",
    "# Outlier Removal\n",
    "class OutlierRemoval:\n",
    "    def __init__(self, lower_limit, upper_limit):\n",
    "        self.lower_limit = lower_limit\n",
    "        self.upper_limit = upper_limit\n",
    "\n",
    "    def remove(self, row):\n",
    "        if row <= self.upper_limit and row >= self.lower_limit:\n",
    "            return row\n",
    "        elif row < self.lower_limit:\n",
    "            return self.lower_limit\n",
    "        else:\n",
    "            return self.upper_limit\n",
    "\n",
    "# Apply outlier removal to all numeric features\n",
    "for feature in train_data.columns:\n",
    "    if train_data[feature].dtype in ['int64', 'float64']:\n",
    "        lower_limit = train_data[feature].quantile(0.25) - (train_data[feature].quantile(0.75) - train_data[feature].quantile(0.25)) * 1.5\n",
    "        upper_limit = train_data[feature].quantile(0.75) + (train_data[feature].quantile(0.75) - train_data[feature].quantile(0.25)) * 1.5\n",
    "        remover = OutlierRemoval(lower_limit, upper_limit)\n",
    "        train_data[feature] = [remover.remove(x) for x in train_data[feature]]\n",
    "        \n",
    "# Apply outlier removal to all numeric features in the testing data\n",
    "for feature in test_data.drop(columns=[\"id\"]).columns:\n",
    "    if test_data[feature].dtype in ['int64', 'float64']:\n",
    "        lower_limit = test_data[feature].quantile(0.25) - (test_data[feature].quantile(0.75) - test_data[feature].quantile(0.25)) * 1.5\n",
    "        upper_limit = test_data[feature].quantile(0.75) + (test_data[feature].quantile(0.75) - test_data[feature].quantile(0.25)) * 1.5\n",
    "        remover = OutlierRemoval(lower_limit, upper_limit)\n",
    "        test_data[feature] = [remover.remove(x) for x in test_data[feature]]\n",
    "\n",
    "# EDA\n",
    "# Step 1: Data Loading and Initial Exploration\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n",
    "print(train_data.describe())\n",
    "print(train_data.info())\n",
    "\n",
    "# Step 2: Missing Values Analysis\n",
    "print(train_data.isnull().sum())\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# Step 3: Correlation Analysis (excluding non-numeric columns)\n",
    "numeric_columns = train_data.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = train_data[numeric_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Target Variable Distribution\n",
    "sns.countplot(x='contentment', data=train_data)\n",
    "plt.title('Distribution of Contentment')\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Feature Distribution\n",
    "sns.histplot(train_data['Arrival Delay in Minutes'], bins=30, kde=True)\n",
    "plt.title('Distribution of Arrival Delay in Minutes')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T17:45:20.109566Z",
     "iopub.status.busy": "2023-12-17T17:45:20.108954Z",
     "iopub.status.idle": "2023-12-17T17:45:22.396696Z",
     "shell.execute_reply": "2023-12-17T17:45:22.395294Z",
     "shell.execute_reply.started": "2023-12-17T17:45:20.109530Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_data = train_data.drop('contentment', axis=1)\n",
    "X_train_data = pd.get_dummies(X_train_data)\n",
    "Y_train_data = pd.get_dummies(train_data['contentment'], drop_first=True)\n",
    "\n",
    "X_train_data = X_train_data.iloc[:, 2:]\n",
    "X_test_data = pd.get_dummies(test_data).iloc[:, 2:]\n",
    "\n",
    "# Step 6: Scaling and PCA Effects\n",
    "data_scaler = StandardScaler()\n",
    "X_train_data_scaled = data_scaler.fit_transform(X_train_data)\n",
    "sns.histplot(X_train_data_scaled[:, 0], bins=30, kde=True, label='Scaled')\n",
    "sns.histplot(X_train_data.iloc[:, 0], bins=30, kde=True, label='Original')\n",
    "plt.title('Effect of Standard Scaling on a Feature')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_data_scaled)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA - Cumulative Explained Variance')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T17:45:22.399392Z",
     "iopub.status.busy": "2023-12-17T17:45:22.398447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard Scaling\n",
    "data_scaler = StandardScaler()\n",
    "X_train_data_scaled = data_scaler.fit_transform(X_train_data)\n",
    "X_test_data_scaled = data_scaler.transform(X_test_data)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train_data_scaled)\n",
    "X_test_pca = pca.transform(X_test_data_scaled)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_pca, Y_train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Define a dictionary to store model performances\n",
    "model_scores = {}\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train, Y_train)\n",
    "y_pred_svm = svm_model.predict(X_val)\n",
    "accuracy_svm = accuracy_score(Y_val, y_pred_svm)\n",
    "model_scores['SVM'] = accuracy_svm\n",
    "print(accuracy_svm)\n",
    "\n",
    "# Nu-Support Vector Machine (NuSVM)\n",
    "nusvm_model = NuSVC(nu=0.5, kernel='rbf', gamma='scale', random_state=42)\n",
    "nusvm_model.fit(X_train, Y_train)\n",
    "y_pred_nusvm = nusvm_model.predict(X_val)\n",
    "accuracy_nusvm = accuracy_score(Y_val, y_pred_nusvm)\n",
    "model_scores['NuSVM'] = accuracy_nusvm\n",
    "print(accuracy_nusvm)\n",
    "\n",
    "# Multi-Layer Perceptron (MLPClassifier)\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, Y_train)\n",
    "y_pred_mlp = mlp_model.predict(X_val)\n",
    "accuracy_mlp = accuracy_score(Y_val, y_pred_mlp)\n",
    "model_scores['MLP'] = accuracy_mlp\n",
    "print(accuracy_mlp)\n",
    "\n",
    "# Boosting using AdaBoost with Decision Trees\n",
    "base_model = DecisionTreeClassifier(criterion='entropy', max_depth=None)\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=base_model, n_estimators=100, random_state=42)\n",
    "adaboost_model.fit(X_train, Y_train)\n",
    "y_pred_ada = adaboost_model.predict(X_val)\n",
    "accuracy_ada = accuracy_score(Y_val, y_pred_ada)\n",
    "model_scores['AdaBoost'] = accuracy_ada\n",
    "print(accuracy_ada)\n",
    "\n",
    "# Bagging using Decision Trees\n",
    "bag_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, max_samples=0.8, oob_score=True, random_state=42)\n",
    "bag_model.fit(X_train, Y_train)\n",
    "y_pred_bag = bag_model.predict(X_val)\n",
    "accuracy_bag = accuracy_score(Y_val, y_pred_bag)\n",
    "model_scores['Bagging'] = accuracy_bag\n",
    "print(accuracy_bag)\n",
    "\n",
    "# Random Forest\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "clf_rf.fit(X_train, Y_train)\n",
    "y_pred_rf = clf_rf.predict(X_val)\n",
    "accuracy_rf = accuracy_score(Y_val, y_pred_rf)\n",
    "model_scores['RandomForest'] = accuracy_rf\n",
    "print(accuracy_rf)\n",
    "\n",
    "# Neural Network Model\n",
    "model_data = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train_pca.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_data.compile(optimizer=Nadam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_data.fit(X_train_pca, Y_train_data, epochs=20)\n",
    "\n",
    "# Get the accuracy on the training data\n",
    "train_accuracy = model_data.evaluate(X_train_pca, Y_train_data)[1]\n",
    "print(f\"Neural Network Accuracy: {train_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.bar(model_scores.keys(), model_scores.values())\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compare model performances\n",
    "best_model_name = max(model_scores, key=model_scores.get)\n",
    "print(f\"Best Model: {best_model_name}, Accuracy: {model_scores[best_model_name]}\")\n",
    "\n",
    "# Use the best model for final predictions on the test set\n",
    "if best_model_name == 'SVM':\n",
    "    final_predictions = svm_model.predict(X_test_pca)\n",
    "elif best_model_name == 'NuSVM':\n",
    "    final_predictions = nusvm_model.predict(X_test_pca)\n",
    "elif best_model_name == 'MLP':\n",
    "    final_predictions = mlp_model.predict(X_test_pca)\n",
    "elif best_model_name == 'AdaBoost':\n",
    "    final_predictions = adaboost_model.predict(X_test_pca)\n",
    "elif best_model_name == 'Bagging':\n",
    "    final_predictions = bag_model.predict(X_test_pca)\n",
    "elif best_model_name == 'RandomForest':\n",
    "    final_predictions = clf_rf.predict(X_test_pca)\n",
    "elif best_model_name == 'NeuralNetwork':\n",
    "    final_predictions = (model_data.predict(X_test_data_scaled) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert predictions to binary values\n",
    "predicted_target_data = (final_predictions > 0.5).astype(int)\n",
    "\n",
    "# Create a DataFrame for the final predictions\n",
    "result_df = pd.DataFrame({'id': test_data['id'], 'contentment': predicted_target_data.flatten()})\n",
    "\n",
    "# Define a mapping function to map numeric predictions to 'content' or 'neutral or discontent'\n",
    "def map_to_contentment(value):\n",
    "    if value == 0:\n",
    "        return 'content'\n",
    "    else:\n",
    "        return 'neutral or discontent'\n",
    "\n",
    "# Apply the mapping function to the 'contentment' column\n",
    "result_df['contentment'] = result_df['contentment'].apply(map_to_contentment)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "result_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "# Print the first few rows of the result DataFrame\n",
    "print(result_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4181266,
     "sourceId": 7223475,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
